---
layout: post
title:  SkipList简单剖析
category: articles
tags: data-structure Skiplist balanced-tree
image:
    feature: head16.jpg
author:
    name:   WuYu
    avatar: bio-photo-alt.jpg
comments: true
share: true
---

####前言

可以使用二叉树表示字典或者顺序队列等数据结构，当数据随机进行插入的时候二叉树性能很好。可是如果数据是按照顺序进行插入，它的性能就会急剧下降。当然你可以打乱输入数据的固有顺序，使其重新具有随机的特性，这样二叉树的性能在绝大多数情况下都是很乐观的。但是在大多数情况下，由于查询都是在线完成的，所以可能没有机会让你一次性得到所有输入数据并对其排序，因此又有了平衡二叉树，它可以通过自平衡调整算法来保证平衡，提高查找性能。

Skip lists是一种可以在一定程度上替代平衡树的数据结构，它通过一个随机数生成器来保证尽量平衡。尽管Skip lists也有性能比较差的情况，但是同样的输入运行多次，不可能每次都恰巧处于最差的情况，换言之就是同样的输入不可能一直差。Skip lists很难出现极度不平衡的情形。举例来说，在一个具有超过250个元素的字典里，查询一个元素的期望次数超过3次的几率小于百万分之一。因此，Skip lists拥有和通过随机插入方法构造的平衡二叉树一样的平衡性，却不需要对输入数据的顺序有硬性要求。通过概率的手段使一个数据结构平衡比显示的调整手段高效的多。对于许多应用，跳表没有树抽象和复杂，这种简化使跳表易于实现，并且能够获得一定的速度提升（时间复杂度不变，常数因子更小）。跳表也很省空间，每个元素平均只需要不多于4/3个指针，不需要维持任何平衡或者优先级信息。

####跳表简要介绍

当我们需要查询一个数据的时候，也许需要遍历一个链表的每一个节点，就像下图。

![](/images/skiplist1.png)

如果链表中数据是有序的，并且每两个节点中有一个节点拥有一个指向其前方两步远的节点的指针，像下图的样子，那么我们只需要检查不超过(n/2)+1个节点就可以找到指定数据。

![](/images/skiplist2.png)

如果像下图那样每4个节点有一个节点有指向其前方4步远的节点的指针，我们就只需检查不超过(n/4)+2个节点就可以了。

![](/images/skiplist3.png)

如果每2^ith个节点拥有一个指向前方2^i步长的节点的指针，我们需要检查的节点数就会降至\log_{2}n, 如下图

![](/images/skiplist4.png)

这种数据结构可以用于快速查询，但是插入删除就不行了。这里我们把一个拥有k个前向指针的节点叫k层节点。如果每第2^i节点有指针指向一个节点距离其前方2^i步长，节点的层数就以一种非常简单的方式进行了划分，50%的节点有一层，25%的节点有两层，12.5%的节点有三层等等。如果节点的层数可以随机选取，像下图那样的话会怎样呢？一个节点第i个前向指针不再指向前方2^(i-1)步长远的节点，而是指向下一个具有i层或者多于i层的节点，插入和删除操作就仅仅需要局部修改操作。当插入一个节点时，节点的层数是随机选取的，并且此后不再改变。层数的设置可能导致Skip lists性能不好，但是我们将会看到这样的设置发生的概率很小。因为这种数据结构是在普通链表的基础上，通过额外指针链向一个间接到达的节点，因此被命名为跳表。

![](/images/skiplist5.png)

####跳表算法

这部分介绍跳表查询，插入和删除操作算法。当数据存在于跳表之中，查询操作返回指定数据，否则返回failure。插入操作就是插入一个指定key的数据（简单起见，没有重复数据）。删除操作删除一个指定key的数据。有了这些基本操作，可以很容易地扩展诸如找最小key对应的数据，找下一个key对应的数据这样的操作。

每个节点代表一个元素，它的层数是随机选择的，和跳表中已有元素个数无关。一个层数为i的节点拥有i个前向指针，从1到i标识。跳表的层数是各节点层数的最大值（跳表为空，层数为1）。一个跳表的表头具有MaxLevel（事先定义的）常数个前向指针,其高于当前跳表层数的前向指针全部指向NIL.

#####初始化

一个NIL元素首先被分配，它被给予了一个比任何合法的key都要大的值，Skip lists的所有层都最终指向NIL。一个新的list被初始化时，它的层数为1，这个list的表头所有前向指针也都指向NIL。

#####查询算法

我们通过前向指针查找一个节点，循环不变式是查找过程中经过的key一定小于待查找的key。算法如图Figure 2所示，当当前层没办法继续前进时，就从下一层开始查找。当我们在第一层无法继续前进时，我们要么就是恰好就在待查询节点前面，要么就是待查询的节点不存在。

![](/images/skiplist6.png)

#####插入和删除算法

我们通过查询和拼接操作插入或者删除一个节点，如图Figure 3所示，插入和删除节点算法如图Figure 4。算法维护一个名字叫update的vector。当查询完成时，update[i]保存第i层最靠近，紧挨着插入或者删除位置的，靠左的那个节点的指针。如果一次插入操作生成的节点的层数高于目前跳表的层数，我们需要更新跳表的最大层数并初始化update vector的适当位置。在每次删除操作执行之后，我们需要检查是否把层数最大的节点删了，是否需要降低跳表的最大层数。

![](/images/skiplist7.png)

![](/images/skiplist21.png)

![](/images/skiplist22.png)

#####如何随机选择节点层数

前文中我们讨论概率分布时选取的概率为1/2，即如果一个节点有第i层前向指针，那么它有1/2的概率拥有第i+1层前向指针。我们现在用p代表这个概率，不再使用1/2。层数产生算法如Figure 5所示，产生的值不依赖跳表中已有元素个数。

![](/images/skiplist9.png)

#####从哪一层开始查找

在一个使用p=1/2概率产生的具有16个元素的跳表中，我们也许会碰到这种情况：9个元素只有1层，3个元素有2层，3个元素有3层，一个元素有14层。如果我们从14层开始查找就会做很多无用的工作。

我们应该从哪开始查询？建议从L=\log_{1/p}n（记做L(n)）高度开始，这层具有期望为1/p个节点（稍后数值分析那会看到产生比L(n)高度高的节点概率很低）。有三种比较常见的方式来处理突然有某个元素层数异常的高这种情况：

1. 不在乎，直接上：因为产生高度异常这种情况概率很低，所以这种节点凤毛麟角，不管，直接查。

2. 不管高度异常节点：这里忽略高于L(n)高度的节点，从L(n)层开始查。但是经过试验发现这种做法并不能显著提升性能，不被提倡。

3. 修改概率：如果我们随机产生的层数比当前跳表最大层数大很多，那么我们“替代”大很多，只给这个新节点赋予层数为跳表目前最大层数+1。经过试验，这种改变效果不错，但是它会破坏我们后面的概率分析，理论研究不提倡，工程实践可以。

#####如何决定最大层数MaxLevel

我们可以选择最大层数为L(N)（N为节点数目），比如p=1/2，节点数为216，那么我们可以选取最大层数为16。

####跳表算法简要数值分析

执行查询，插入和删除的操作都依赖于查询操作时间复杂度，那我们就重点分析查询的期望代价。我们从分析跳表期望高度开始，一个节点具有i>=1的高度的概率为1/(p^i)，因此，level i至少有一个节点的概率为

P<n/(p^i)

因为n个互不相容的事件中任何一个发生的概率都不超过这n个事件发生的概率和。跳表高度超过i的概率要小于至少有一个节点具有i层的概率，这个值不超过P，我们定义一个常数c>1，因此跳表高度高于clogn的概率要小于1/(n^(c-1))，进而推出跳表高度h低于clogn的概率要大于1-1/(n^(c-1))。我们可以看出很大概率上，跳表高度h是O(logn)。事实上，层数产生的随机算法我们已经给出，如图Figure 5，我们定义Maxlevel的值为\log_{1/p}n，是O(logn)的。高度是O(logn)的情况下，我们继续分析跳表查找平均复杂度。

我们逆序循着搜索路径来看，在探寻过程中任意时刻我们处于如图Figure 6的情况a——我们在node x的ith的前向指针上，假设我们对x左边节点和x自身的层数一无所知，只知道x节点当前层数至少是i的。如果node x层数是i，我们就处于b情况，概率是1-p。如果node x的层数大于i，我们就在c情况，概率是p。定义C(k)为我们攀爬k层高度跳表的期望开销（一般以走的路程经过的节点数为表征），那么C(k)=1+(1-p)C(k)+pC(k-1)，C(k)=k/p。说明查找时间复杂度正相关于跳表层数，由于跳表层数时间复杂度是O(logn)，所以平均查找时间复杂度为O(logn)

![](/images/skiplist10.png)


最近由于实验室需要设计和实现一个支持OLAP的列式内存数据库，所以对一些典型的同类型数据库产品进行了一番调研。这里我把SAP HANA里基于内存的列式数据库索引引擎p*Time中所使用的索引技术整理和记录了一下，希望对大家能有所帮助。

####wikipedia上对HANA的定义如下：
> SAP HANA, short for "High-Performance Analytic Appliance" is an in-memory, column-oriented, relational database management system developed and marketed by SAP AG. It runs massively parallel, thus exploiting the maximum out of multicore processors and subsequently enabling very fast query execution.

####概述

HANA采用读写分离策略，数据更新作用在一个专门为写优化的区域（delta partition），这个区域通常都很小并且采用树的结构（比如B类树）建立相关索引。而只读区域（main partition）一般都很大，并且同样需要建立索引以提高事务和分析业务的性能。p*Time提出了一套独特的main partition的索引方案Group-key Index，该方案在查询执行时能急剧降低内存消耗，因此对内可以快速进行索引查询，对外可以快速执行联合查询，这对OLTP和OLAP来说都非常有利。

####核心数据结构

为了更好的节省内存开销，Group-key Index索引方案中的大部分数据结构都采用了位压缩，比如在32位机器上，一个整型占用4个字节，如果我们要表示的数不是很大的情况下，这往往都是浪费内存的，因此更“经济”的解决方案是如果我们所需要的最大的数为n，那么就把表所要表示的数的位数限定为$ \log_2n $。尽管OLAP型业务往往需要操作整个表或者域，甚至对表进行多维度联合查询，但是对于列式数据库中拥有字典索引的列，p*Time采用疏松索引来取代密集索引以获得更高的查找效率。

p*Time所用到的核心数据结构有以下4个，其中前两项是main partition需要的，而后两项是Group-key Index需要的

* 排好序的字典 ( $ U_M^j $ )
* 位压缩过的属性向量表 ( $ V_M^j $ )：存储了标识原始数据在字典中的偏移，也叫value-ids。
* 偏移向量表 ($ I^j $)：辅助性数据结构，负责把指定的value-id映射到其在属性向量索引表的偏移。
* 属性向量索引表 ($ P^j $)：存储value-id在属性向量中的位置。

####下文这四种数据结构均以符号标示。

它们之间的关系见下图所示：

![relation](/images/fast1.png)

####如何查找

我来举个简单的例子说明这4个数据结构是如何协作的，比如需要查询charlie的位置（HANA叫RowID），首先在$ U_M^j $中用二分查找找到charlie，然后读出$ I^j $中相同偏移的值（1）以及下一偏移存储的值（3），注意字典项和偏移向量表项一一对应。拿到1和3说明charlie这个单词在$ P^j $中偏移为1和2，因为$ I^j $中相邻两项记录的是左闭右开区间。然后在$ P^j $中偏移为1和2处拿出值5和6，这步一般可以一次性取出值，因为$ U_M^j $中的指定值如果出现不止一次，它们在$ P^j $中的相关信息都是连续存放的。5和6就是该字符串的RowID，也就是其位置，而且可以发现$ V_M^j $中偏移为5和6位置的value-id都为1，恰好是charlie在$ U_M^j $中的偏移。

####如何重建Group-key Index

在拥有$ U_M^j $和$ V_M^j $的情况下，重建Group-key Index的步骤：

1. 生成$ I^j $：先创建一个空的$ I^j $（每一项都填0），长度和$ U_M^j $长度相同，遍历$ V_M^j $查找value-ids的出现次数，比如上图，假如需要根据左面两个数据结构生成Group-key Index，apple的value-id是0，在$ V_M^j $中查找0出现的次数发现只有1个，就在$ I^j $第1项填1（0+1），注意填$ I^j $时从第一项开始（所有数据结构的偏移都是从0开始的，程序猿应该很好理解）。同理，charlie的value-id是1，在$ V_M^j $查找发现出现2次，在$ I^j $第2项填上一次求得结果加上出现次数，即1+2=3，以此类推直至扫到字典末尾。
2. 生成$ P^j $：扫描$ I^j $，获取每一项的键值对（key,value），key是$ I^j $每一项的位置：第0项，第1项等等，value就是该位置存储的值，也是该value-id映射在$ P^j $中的位置信息，比如上图取出（0,0），（1,1），（2,3）......。拿着key去$ V_M^j $中查询，比如key 0在$ V_M^j $中偏移是4，这是我们要填入$ P^j $的值，key 0对应的value即是要填入的位置，这里是0，所以把4填入$ P^j $中偏移为0的位置。然后用$ I^j $的下一项键值对的值减去本键值对的值来获取该key在$ V_M^j $中出现的次数，这里发现1-0=1，说明只出现1次，所以已经填入完毕。但是对于键值对（1,1）发现该key出现的次数是3-1=2次，所以在$ V_M^j $中搜索key 1要搜两次并把其在$ V_M^j $中的位移依次填入$ P^j $的相关位置，以此类推，直至扫描完$ I^j $。

####如何生成main partition中的字典和属性向量

如下图所示：

![rebuild main](/images/fast2.png)

不要被图吓到，其实操作步骤很简单。首先必须要说明一下，我们刚才讲的索引数据结构只适用于main partition，那么对于delta partition是怎样进行索引的呢？其实前面也提到了就是B+树。上图已经给出了步骤我这里解释一下，首先标示为Inputs Step 1是第一步我们需要的输入，Outputs Step 1就是我们第一步需要输出的东西，包括新字典$ U'^j_M $，辅助性数据结构增量向量表$ X_M^j $和delta partition的属性向量表$ V_D^j $。$ U'^j_M $由$ U_M^j $和delta partition中的B+树合并而成，我们首先同时扫描$ U_M^j $和B+树的叶子节点，按照字符串顺序（字典顺序）做归并排序即可生成$ U'^j_M $，在生成$ U'^j_M $的同时需要生成$ X_M^j $，比如新插入个bodo，这是$ U_M^j $没有的，就在bodo所在的$ U'^j_M $偏移1开始，依次把$ X_M^j $中的每一项加1，如上图中的$ X_M^j $所示。delta partition中的$ V_D^j $就根据新字典来填即可。

Inputs Step2的输入部分是$ X_M^j $ ，$ V_M^j $和刚才第一步新生成的$ V_D^j $ ，Outputs Step 2输出的就是新的属性向量$ V'^j_M $ ，那么它是如何生成的呢？先把$ V_M^j $根据$ X_M^j $做一个更新然后和$ V_D^j $做合并，比如$ V_M^j $中第一项是4，找到$ X_M^j $中偏移为4的项值是1，所以将5（4+1）填入$ V'^j_M $第一项，以此类推。全部更新完成后直接把$ V_D^j $放到$ V'^j_M $末尾，也就是简单地合并即可。

这样新的字典和属性向量就生成了，之前还有Group-key Index的偏移向量和属性索引向量的生成，有没有觉得很麻烦，其实还有一种更省内存的方式来同时生成这4个向量数据结构。如下图所示：

![rebuild all](/images/fast3.png)

这里给出伪代码，我就不详细解释了，其实就是我刚才讲的重建Group-key Index和构建mian partition中字典和属性向量步骤的融合，当然中间HANA又用了一些小技巧和辅助性数据结构，试着跟着代码走一下相信大家就可以理解如何操作了，其实这个算法本身并不是难点，而是如何实现以尽量节省内存开销才是p*Time重点关注的事情，也是它的一个核心技术。

![code](/images/fast4.png)

如果大家对此还觉得有些绕，可能是因为之前有一些是HANA自身架构设计导致的，建议看一下HANA的白皮书 [^1]，相信就会有比较深刻的认识。

####本文源自论文 [^2]

[^1]: <http://www.saphana.com/docs/DOC-1381>

[^2]: <http://adms-conf.org/faust_adms12.pdf>

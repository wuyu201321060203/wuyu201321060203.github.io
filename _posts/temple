尽管十几年前对分布式数据库系统的理论研究就已经开展了，但是直到近几年计算机工业界才真正广泛地运用分布式数据库。这里面有两个原因：

1. 现代应用的数据和事务的吞吐量急剧增长，需要一个弹性的具有扩展性的数据库系统。
2.  随着商业全球化进展，将分布在世界各地的用户需要的数据存储在离他们较近的区域，降低网络存取延时，提高服务质量的需求越发强烈。

过去十年也涌现了一大批试图获取高扩展性或者具有跨区域快速存取能力的分布式数据库系统，比较典型的有：SimpleDB/Dynamo/DynamoDB，Cassandra，HBase/BigTable，MongoDB等等。

分布式数据库系统的设计是极其复杂，因此任何能够帮助设计架构师简化设计，有依据地对系统设计中的特性进行权衡的理论工具都是求之不得的，在这方面，CAP理论无疑是“家喻户晓”。然而，自从这项理论被证明以来，CAP被误理解和误用的现象屡见不鲜，并且对商用系统设计产生了不可估量的危害（包括很多逼格很高的大学教授也并不是真正理解CAP）。有很多人错误地概括总结，将CAP理论的限制强加给正常运行环境中的分布式系统，在最初设计和实现时就进行了错误的取舍，造成分布式系统的“先天残疾”。实际上，CAP仅仅是说，当系统已经产生了特定类型的错误，这个时候一些性质不能兼得，而不是说系统在其正常运行时这些性质就不能同时具有。

虽然在分布式系统正常运行时没有CAP限制，但并不是说可以做出天使系统，相反，有一个更基本的并且比CAP对分布式系统更具影响的限制广为熟知，那就是一致性和服务延迟之间的权衡。CAP和一致性/服务延迟权衡都是重要的，因此有必要对这两个权衡或者说限制进行归一总结，从而更好的理解现代分布式数据库系统设计，在这点上耶鲁大学提出的PACELC理论完成了这个很有价值的工作。

####CAP回顾与分析

CAP理论基本阐述了这样一种思想，设计者在设计分布式数据库时只能在一致性(consistency)，可用性(availability)和分区容忍性(partition tolerance)这三个性质中选择两个，三者不能同时兼得，因此只能有CA，CP，AP系统是可能的。许多现代的分布式数据库，像SimpleDB/Dynamo，Cassandra，Voldemort等等好像也都实证了这一理论，舍弃了一致性保证，保留了可用性和分区容忍性。这后面有一个表面上让人可以信赖的理由：因为任何分布式数据库都必须保证分区容忍性，根据CAP，必须要在可用性和一致性两者中选其一，对于在线服务类应用，高可用性又是必须的，所以不好意思，一致性只能被牺牲。然而，这个理由的逻辑是错误的，也并不是深谙CAP之道。CAP真正的意思不是分区容忍导致需要在一致性和可用性上做取舍，而是需要分区容忍且网络分区已经存在。这个理论仅仅说网络分区发生导致系统只能在一致性和可用性之间选其一（要注意，选其一不是说完全舍弃某一方，只是削弱）。然而网络分区发生的可能原因有很多：
- 服务在广域网上还是本地集群
-  系统硬件的质量
-  副本的等级
........
通常来说，网络分区发生的概率相比其他严重的错误来说很低很低。

承上，CAP没有对正常状况下的系统强加任何限制，所以也就不要在也许没有网络分区的情况下就断然降低一致性支持，实际上，在没有网络分区的情况下，做一个CA系统是很正常的。那为什么那么多流行的分布式数据库都降低了一致性支持呢？

####一致性/服务延迟限制

想要搞明白现代分布式数据库设计中为什么降低一致性，我们需要联系它们的应用背景作分析。亚马逊设计的Dynamo是为电子商务平台（比如购物车）服务的，Facebook的Cassandra也是为收件箱查询服务的，LinkedIn创造Voldemort也是由于需要处理其网站上广泛的在线更新操作。我们可以发现这些系统的一些共同点：它们都是为在线用户提供数据服务的，而在线服务一个显著的特征就是延迟零容忍：高延迟很可能导致用户体验不佳而转向其他类似服务。因此这里就存在了一个限制，就是一致性和服务延迟之间不可调和，即使没有网络分区，这个限制也或者权衡也必须存在。

为什么说一致性和服务延迟不可调和？在线服务必须高可用，这是基本前提，而这个基本前提的保证必须采用数据复制技术，只要系统服务时间够长，某个节点产生故障司空见惯，如果不想因为它上面的数据不能服务而导致系统不可用，就需要事先对数据做副本，也就是说系统即使运行在正常情况下，数据复制也是跑不了的。这个限制和CAP的显著区别就是：这个限制为了预防错误，而CAP是错误已经产生。上述的那些分布式数据库设计时考虑的很重要一点就是在广域网条件下需要高可用，因此要进行跨域数据复制。

####数据复制分析

正如上面所言，只要进行数据复制，必然要在一致性和可用性上做选择。数据复制只有三种策略，我们对每一种策略情形下一致性/服务延迟限制的存在之处做分析。

(1) 数据更新同时发往所有副本

 如果这种更新不先经过一个预处理或者走一个一致性协议，那么不一致很可能发生，因为你没法保证并发的更新在每一个副本上更新的顺序保持一致。另一方面如果更新要走预处理或者运行一致性协议，那么延迟是避免不了的。
(2) 数据更新发往众所周知节点

我所说的众所周知节点就是所谓的master节点。这个master几点需要处理所有数据的更新操作，更新的顺序很容易保证，由master节点按照一定复制策略将更新发往其他所有副本。复制策略有以下三种：
强同步复制：master节点必须同步等待副本完成更新（也可以是日志固化完成就可以）才能进行接下来操作，这种策略一致性是没问题的，但是在WAN下同步等待所有副本完成更新无疑增加了服务延迟。

- 

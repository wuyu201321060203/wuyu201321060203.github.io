---
layout: post
title:  内存分配器jemalloc学习笔记
category: opinions
tags: jemalloc memory-allocation malloc

image:
    feature: head18.jpg

author:
    name:   WuYu
    avatar: bio-photo-alt.jpg

comments: true
share: true
---

####引言

jemalloc是一个能够快速分配/回收内存，减少内存碎片，对多核友好，具有可伸缩性的内存分配器。为更好的支持多核内存分配的需要，jemalloc首次在FreeBSD中引入，用于取代之前的phkmalloc，而后被facebook发扬光大，成为了业界流行的内存分配解决方案。

####设计思想

jemalloc在结合其他内存分配器优势的同时也引入一些自己独特的机制，下面这些观点和设计哲学构成了jemalloc：

- 针对小内存分配场景引入一系列size类，8bytes，16bytes，32bytes等等，分配小内存时从相应size类分配（可以理解成dlmaooc里的分箱），并且遵循低地址优先原则，这样可以极大避免内存碎片。

- 谨慎选择size类的数目和间隔，兼顾内存内零头和外零头。

- 元数据占用空间尽量少，除内存碎片以外，jemalloc元数据的空间占用小于内存总用量的2%。

- 减少活动页面数目，即尽量充分利用空间，将数据紧紧存储在连续几页，既可以利用局部性，又能减少swap。

- 最小化锁竞争，jemalloc从lkmalloc引入线程独立的arena机制，从google的tcmalloc引入thread cache机制，尽量减少线程之间分配回收内存时的锁争用。

- 如果做不到通用，说明不够好

####jemalloc核心架构

jemalloc采用多级内存分配，根据内存对象的大小，jemalloc将其分为small object, large object和huge object三类。

- Small objects的size以8字节，16字节，32字节等分隔开的，小于页大小。

- Large objects的size以分页为单位，等差间隔排列，小于chunk的大小。

- Huge objects的大小是chunk大小的整数倍。

small objects和large objects由arena来管理， huge objects由线程间公用的红黑树管理。对于64位操作系统，假设chunk大小为4M，页大小为4K，内存等级分配如下图：

![](/images/je1.png)

在 jemalloc 中，整块批发内存，之后或拆开零售，或整块出售。整块批发的内存叫做 chunk，chunk 的大小为 4MB（可调）或其倍数，且为 4MB 对齐。由于chunk粒度太大，只有为huge objects分配内存才需要这种粒度，因此chunk进一步拆分为不同粒度的run，分配small/large objects都以run为单位。但是对于small objects来说，这个粒度还是大了点，因此又分成不同大小的bin，分配时找对应的bin，由bin提供小对象需要的内存，但要注意羊毛出在羊身上，bin其实也是通过其管理的run提供内存的，相当于在run上面盖了一层元数据的帽子。另外由于chunk都是等大小，这样可以通过指针操作在常量时间内找到分配small/large objects的元数据, 在对数时间内（红黑树）定位到分配huge objects的元数据。 chunk，run，bin管理的都是自己那部分内存资源，因此还需要一个角色在chunk，run，bin的基础上，以全局观角度去管理系统内存，这就是Arena。为了更好的线程可扩展性，jemalloc采用多个arena管理内存，它的数目一般为物理机CPU核数的4倍。每个线程独立管理自己的内存，负责small和large的内存分配，减少了多个线程间的锁竞争。线程按第一次分配small或者large内存请求的顺序Round-Robin地选择arena。并且从某个arena分配出去的内存块，在释放的时候一定会回到该arena。此外， jemalloc引入线程缓存tcache来解决线程之间的同步问题， 通过对small和large对象的缓存，实现通常情况下内存的快速申请和释放。下图是经典的jemalloc的架构图，主要涉及前面所讲的四个数据结构：arena，bin，chunk，run。

![](/images/je2.png)

（1）Arena：每个arena内都会包含对应的管理信息，记录该arena的分配情况。每个Arena都有一定额度的chunks，下图展示了Arena数据结构的内部信息。

![](/images/je3.png)

（2）Bin：不同bin管理不同size大小的run，在任意时刻， bin中会针对当前size保存一个run用于内存分配，每个bin里维护一棵红黑树维护空闲的run，下图展示了Bin数据结构内部信息。

![](/images/je4.png)

（3）Run：一个run实际上就是chunk里的一块区域，大小是page的整数倍，在run的最开头会存储着这个run的信息，比如还有多少个块可供分配，下一块可分配区域的索引，见下图。

![](/images/je5.png)

run中采用bitmap记录分配区域的状态， 相比采用空闲列表的方式， 采用bitmap具有以下优点：bitmap能够快速计算出第一块空闲区域，且能很好的保证已分配区域的紧凑型。分配数据与应用数据是隔离的，能够减少应用数据对分配数据的干扰。对很小的分配区域的支持更好。run的内存布局如下：

![](/images/je6.png)

run的内存布局由arena_bin_info_s确定，与bin分开存储，与其他数据结构不同的是，arena_bin_info_s对于所有arena的不同size保持一份拷贝，而不是每个arena的不同size保存一份拷贝。这样既可以减少内存使用，又能避免缓存冲突。还需注意的是只有bin管理的run才有这样的内存布局，region之说。为large objects准备的run没有这些东西，直接按页管理分配。

（4）Chunk：chunk是具体进行内存分配的区域，目前的默认大小是4M。chunk以page（默认为4K)为单位进行管理，每个chunk的前几个page（默认是6个）用于存储chunk的元数据，后面跟着一个或多个page的runs. 后面的runs可以是未分配区域，多个小对象组合在一起组成run, 其元数据放在run的头部；大对象构成的run, 其元数据放在chunk的头部。chunk数据结构信息见下图

![](/images/je7.png)

Arena-Bin-Run-Chunk的一个简单关系图如下：

![](/images/je8.png)

（5）tcache：tcache为线程对应的私有缓存空间，用于减少线程分配内存时锁的争用，提高内存分配的效率。如果使用tcache时，jemalloc分配内存时将优先从tcache中分配，只有在tcache中找不到才进入正常的分配流程。tcache数据结构如下：

![](/images/je10.png)

每个tcache也有一个对应的arena, 这个arena内部也包含一个tbin数组来缓存不同大小的内存块，与arena中的bin对应，只是长度更大一些，因为它需要缓存更大的内存块，tcache中对象的缓存，没有对应的run的概念。

####jemalloc内存分配策略

![](/images/je11.png)

如上图所示，jemalloc的内存管理采用层级架构，分别是线程缓存tcache，分配区arena和系统内存memory，不同大小的内存块对应不同的分配区。每个线程对应一个tcache，负责当前线程使用内存块的快速申请和释放，避免线程间锁的竞争和同步。arena的具体结构在前文已经提到，采用内存池的思想对内存区域进行合理的划分和管理，在有效保证低内存碎片的情况下实现不同大小内存块的高效管理。system memory是系统的内存区域。

#####small object

1. 当jemalloc支持tcache时，small object的分配从tcache开始。
2.  tcache不中则从arena申请run并将剩余区域缓存到tcache。
3.  若arena中不能分配则从系统内存中申请chunk，加入arena进行管理并切成run，go to step2。
4.  不支持tcache时， 则直接从arena中申请，go to step2。

#####large object

1. 当jemalloc支持tcache时，如果大对象所需内存小于tcache_maxclass，则从tcache开始分配。
2.  tcache不中则从arena申请，只申请需要的内存块，不做多余cache。
3.  若arena中不能分配则从system memory中申请。
4.  当大对象所需内存大于tcache_maxclass或者jemmalloc不支持tcache时， 直接从arena中申请。

#####huge object

huge object的内存不归arena管理，直接采用mmap从system memory中申请并由一棵与arena独立的红黑树进行管理。

jemalloc的内存分配和释放的具体细节可以参考文章 [^1] [^2] [^3] [^4]，这里不作详细介绍，jemalloc的内存分配就介绍完毕，这里做一个简单的总结：

1. jemalloc引入线程缓存tcache, 分配区arena来减少线程间锁的争用, 保证线程并发扩展性的同时实现了内存的快速申请释放。
2. 采用arena管理不同大小的内存对象在保证内存高效管理的同时减少了内存碎片。
3. 引入红黑树管理空闲run和chunk，相比链表具有了更高的效率。
4. 在run中采用bitmap管理可分配区域来实现管理和数据分离，且能够更快地定位到空闲区域。
5. 引入了多层cache，基于内存池的思想，虽然增加了内存占用，但实现了内存的快速申请释放，除了tcache，还有bin中的runcur， arena中的spare等。

[^1]: <http://brionas.github.io/2015/01/31/jemalloc%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/>

[^2]: <http://brionas.github.io/2015/01/31/jemalloc%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%A0%B8%E5%BF%83%E6%9E%B6%E6%9E%84/>

[^3]: <http://www.tinylab.org/memory-allocation-mystery-%C2%B7-jemalloc-a/>

[^4]: <http://www.tinylab.org/memory-allocation-mystery-%C2%B7-jemalloc-b/>
